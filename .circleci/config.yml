# Use the latest 2.1 version of CircleCI pipeline process engine. See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1
# command section
commands:
  
  delete_stack:
    steps:
      - run:
          command: |
            aws cloudformation delete-stack --stack-name prod-${CIRCLE_WORKFLOW_ID}

# Use a package of configuration called an orb.
orbs:


# Orchestrate or schedule a set of jobs
jobs:

  create_infrastructure:
    docker :
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Ensure backend infrastructure exist
          command: |
            aws cloudformation deploy \
            --stack-name prod-${CIRCLE_WORKFLOW_ID} \
            --template-file template.yml
      - run:
          name: write in inventory
          command: |
            aws ec2 describe-instances \
            --query 'Reservations[*].Instances[*].PublicIpAddress' \
            --filters "Name=tag:aws:cloudformation:stack-name,Values=prod-${CIRCLE_WORKFLOW_ID}" \
            --output text >> ~/inventory.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - inventory.txt
      - run:
          command: |
            return 1
      - run:
          command: |
            aws cloudformation delete-stack --stack-name prod-${CIRCLE_WORKFLOW_ID}
      
  execute_playbook:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: ["f4:e4:5b:28:26:fd:01:9c:29:bd:48:d1:32:20:19:31"]
      - run:
          name: Install dependencies
          command: |
            apk add --update ansible # install the dependencies needed for your playbook
      - attach_workspace:
          at: ~/
      - run:
          name: Configure server
          command: |
            export ANSIBLE_HOST_KEY_CHECKING=False
            ansible-playbook -i ~/inventory.txt playbook.yml

  smoke_test:
    docker:
      - image: alpine:latest
    steps:
      - checkout
      - run: apk add --update curl
      - run:
          name: smoke test!
          command: |
            if curl -s --head "ec2-54-159-26-135.compute-1.amazonaws.com:3000"
            then
              echo "reached page!"
              return 0
            else
              echo "failed!"
              return 1
            fi
  
  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: create and deploy front end
          command: |
            aws cloudformation deploy \
            --template-file bucket.yml \
            --stack-name "${CIRCLE_WORKFLOW_ID:0:7}" \
            --parameter-overrides PipelineID="${CIRCLE_WORKFLOW_ID:0:7}"
      - run: aws s3 sync . s3://"${CIRCLE_WORKFLOW_ID:0:7}" --delete

  get_last_deployment_id:
    docker :
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
      - run: yum install -y tar
      - run: yum install -y gzip
          name: get last deployment id please
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text >> ~/last_deployment_id.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - last_deployment_id.txt

  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: cloudfront execution
          command: |
            aws cloudformation deploy \
            --template-file cloudfront.yml \
            --stack-name production-distro \
            --parameter-overrides PipelineID="${CIRCLE_WORKFLOW_ID}"

  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - attach_workspace:
          at: ~/
      - run:
          command: |
            aws s3 rm "s3://${OldPipelineID}" --recursive
            aws cloudformation delete-stack --stack-name "${OldPipelineID}"
# aws s3 rm "s3://$(cat ~/last_deployment_id.txt)" --recursive
# aws cloudformation delete-stack --stack-name "$(cat ~/last_deployment_id.txt)"

workflows:
  # Name the workflow "welcome"
  infrastructure:
    # Run the welcome/run job in its own container
    jobs:
      - create_and_deploy_front_end
      - get_last_deployment_id:
          requires:
            - create_and_deploy_front_end
      - promote_to_production:
          requires:
            - create_and_deploy_front_end
      - clean_up_old_front_end:
          requires:
            - promote_to_production
            - get_last_deployment_id
